# Template for the config file,
# Defaults to config.yml in ./config.
# The config tool defaults to config/config.config-tool.yml, and uses the same config 
# options, though only EndpointURL and if needed username/password/secure are required.
# The values here are generally the default values, except for the contents of lists etc.
# Your config file can contain only a subset of these config options. Any extra options will
# cause the extractor to fail.

# Version of the config schema
version: 1

source:
    # The URL of the OPC-UA server to connect to
    endpoint-url: "opc.tcp://localhost:4840"
    # Auto accept connections from unknown servers.
    # There is not yet a feature to accept new certificates, but you can manually move rejected certificates to accepted.
    # Paths are defined in opc.ua.net.extractor.Config.xml
    auto-accept: false
    # How often the client requests updates to subscribed variables.
    # 0 updates at maximum rate set by server
    # This decides the maximum rate points are pushed to CDF. Higher reduces network and server load.
    publishing-interval: 500
    # How often the server requests updates from the source system (the source system is often the server itself)
    # 0 uses maximum rate set by server
    # Lower increases server load. This should be set to below the maximum update frequency of the source system.
    sampling-interval: 100
    # Length of internal server queue for each subscribed item. < 2 means that any updates occuring between publish requests are lost.
    queue-length: 10
    # OPC-UA username, leave blank for anonymous user. (no authentication)
    username:
    # OPC-UA password
    password:
    # Use secured connection
    secure: false
    # If true, force restart the extractor on disconnect. Required for some servers
    force-restart: false
    # Completely exit the extractor on failure, instead of doing an internal restart. Internal reset should re-initialize everything relevant,
    # but this can be set to do restart with some external tool instead.
    exit-on-failure: false
    # Max sizes of various requests to OPC-UA. Defaults are usually okay, but some servers may fail with too large request sizes
    # Maximum number of results per browse or browseNext operation
    browse-chunk: 1000
    #Max number of nodes to browse at the same time. Higher is much faster, but may be restricted by the server.
    browse-nodes-chunk: 1000
    attributes-chunk: 1000
    subscription-chunk: 1000

# Config for reading of history from the server
history:
    # Enable/disable history synchronization from the OPC-UA server to CDF.
    # This is a master switch covering both events and data
    enabled: false
    # Enable or disable data history on historizing nodes. "Enabled" must be true.
    data: true
    # Enable/disable backfill behavior. If this is false, data is read using frontfill only. (Pre 1.1 behavior)
    # This applied to both datapoints and events.
    backfill: false
    # Max number of datapoints per history read request, 0 for server specified
    data-chunk: 1000
    # Max number of simultaneous nodes per historyRead request for data
    data-nodes-chunk: 100
    # Max number of events per history read request, 0 for server specified
    event-chunk: 1000
    # Max number of simultaneous nodes per historyRead request for events
    event-nodes-chunk: 100
    # The earliest timestamp to be read from history on the OPC-UA server, in milliseconds since 1/1/1970.
    start-time: 0
    # Granularity to use when doing historyRead, in seconds. Nodes with last known timestamp within this range of eachother will
    # be read together. Should not be smaller than usual average update rate
    # Leave at 0 to always read a single node each time.
    granularity: 600

# List of pushers, the type must be identified using a Yaml tag. Each element results in a pusher, so it is possible
# to push multiple times to the same system, for example in order to push to multiple projects in CDF.
# List of accepted tags:
# - !cdf, A pusher for CDF.
# - !influx, Pusher for InfluxDB
# - !mqtt, pusher for CDF through a one-way MQTT connection.
pushers:
    - !cdf
        # The project to connect to in the API
        project:
        # Cognite api key
        api-key:
        # Cognite service url
        host: "https://api.cognitedata.com"
        # Debug mode, if true, Extractor will not push to target
        debug: false
        # Replace all instances of NaN, Infinity or values greater than 1E100 with this floating point number. If left empty, ignore instead.
        non-finite-replacement:
        # Whether to read start/end-points on startup, where possible. At least one pusher should be able to do this,
        # otherwise back/frontfill will run for the entire history every restart.
        # The CDF pusher is not able to read start/end points for events, so if reading historical events is enabled, one other pusher
        # able to do this should be enabled.
        read-extracted-ranges: true
        # Data set to use for new objects. Existing objects will not be updated
        data-set-id:
        # Chunk sizes in CDF requests
        latest-chunk: 100
        earliest-chunk: 1000
        time-series-chunk: 1000
        asset-chunk: 1000

    - !influx
        # Host URI, ex localhost:8086
        host:
        # Influx username
        username:
        # Influx password
        password:
        # Database to connect to, will not be created automatically
        database:
        # Debug mode, if true, Extractor will not push to target
        debug:
        # Replace all instances of NaN or Infinity with this floating point number. If left empty, ignore instead.
        non-finite-replacement:
        # Whether to read start/end-points on startup, where possible. At least one pusher should be able to do this,
        # otherwise back/frontfill will run for the entire history every restart.
        read-extracted-ranges: true
        # Max number of points to send in each request to influx
        point-chunk-size: 100000

    - !mqtt
        # TCP Broker URL
        host:
        # TCP Broker port
        port:
        # MQTT broker username
        username:
        # MQTT broker password
        password:
        # True to enable TLS
        use-tls:
        # Mqtt client id. Should be unique for a given broker.
        client-id: cognite-opcua-extractor
        # Data set to use for new objects. Existing objects will not be updated
        data-set-id:
        # Assets topic
        asset-topic: cognite/opcua/assets
        # Timeseries topic
        ts-topic: cognite/opcua/timeseries
        # Events topic
        event-topic: cognite/opcua/events
        # Datapoints topic
        datapoint-topic: cognite/opcua/datapoints
        # Set to enable storing a list of created assets/timeseries to local litedb.
        # Requires the StateStorage.Location property to be set.
        # If this is left empty, metadata will have to be read each time the extractor restarts.
        # Default is empty
        local-state: mqtt_create_states
        # Timestamp in ms since epoch to invalidate stored mqtt states.
        # On extractor restart, assets/timeseries created before this will be attempted re-created in CDF.
        # They will not be deleted or updated.
        invalidate-before: 0
        # If true, pusher will not push to target
        debug: false
        # Replace all instances of NaN, Infinity or values greater than 1E100 with this floating point number. If left empty, ignore instead.
        non-finite-replacement:
        

# If a pusher fails to push data for some reason, the failure buffer will automatically store the data,
# then add it back into the queue once a push succeeds.
failure-buffer:
    # If false, buffering is disabled
    enabled: false
    # Use influxdb as buffer
    # Points will be written to influxdb on failure unless "write" is false, and read once pushing succeeds again.
    # They will not be deleted, even once pushed to CDF.
    # This, however, allows a remote buffer, and it allows using an existing influxdb pusher as a buffer, with write set to false.
    influx:
        host:
        username:
        password:
        database:
        # If true, write failed datapoints to influx, otherwise, only read.
        # This should be false if there is a pusher targeting the influxdb database.
        write: true
        # Max number of points to send in each request to influx
        point-chunk-size: 100000
        # Store the state of which points/ranges are persisted to influxdb to local state storage. Requires the
        # StateStorage.Location option to be set
        state-storage: false
    # There are two possible solutions for local storage. The queue is ACID, and is more reliable if the amount of data is low,
    # expected breaks are short, and is more reliable. The binary buffers are much faster, but potentially less reliable.
    # If true, store failed points in a queue in the state storage. The StateStorage.Location option must be set for this to work.
    local-queue: false
    # The alternative is a simple binary file containing the points. There is no safety, and a bad write can corrupt the file,
    # but it is very fast.
    # Path to a local binary buffer file for datapoints.
    datapoint-path:
    # Path to a local binary buffer file for events.
    # The two buffer file paths must be different.
    event-path:

# Periodically store state in a local database to speed up starting, by not having to read state from destinations
# This allows you to set the read-extracted-ranges option to false on the pushers without having to read all of history on startup.
# If the OPC-UA server does not support history this does nothing.
state-storage:
    # Path to .db file used by the state storage
    location: "buffer.db"
    # Interval between each write to the buffer file, in seconds. 0 or less disables the state storage.
    interval: 10


logger:
    # Writes log events at this level to the Console. One of verbose, debug, information, warning, error, fatal.
    # If not present, or if the level is invalid, Console is not used.
    console:
        level:
    # Writes log events at this level to a file. Logs will roll over to new files daily.
    # If not present, or if the level is invalid, logging to file is disabled.
    file:
        level:
        # Path for logging output. If not present, logging to file is disabled.
        path: # "logs/log.txt"
        # Maximum number of logs files that are kept in the log folder.
        retention-limit: 31
        # Rolling interval for log files. Either "day" or "hour".
        rolling-interval: "day"
    
metrics:
    # Start a metrics server in the extractor for Prometheus scrape
    server:
        host:
        port: 0
    # Multiple Prometheus PushGateway destinations:
    push-gateways:
        - host:
          job:
          username:
          password: 

extraction:
    # Global prefix for externalId towards pushers. Should be unique to prevent name conflicts in the push destinations.
    # The externalId is: IdPrefix + NamespaceMap[nodeId.NamespaceUri] + nodeId.Identifier
    id-prefix: "gp:"
    
    # Specify prefixes on DisplayName to ignore.
    ignore-name-prefix:
        # -prefix1
    
    # Specify specific DisplayNames to ignore.
    ignore-name:
        # -name1
    
    # List of NodeIds corresponding to DataTypes that should be ignored.
    ignore-data-types:
        # - NamespaceUri:
        #	NodeId:

    # Delay in ms between each push of data points to targets
    data-push-delay: 1000
    
    # Maximum size of array variables. Only arrays with the ArrayDimensions property in opc-ua specified will be used,
    # leave at 0 to only allow scalar values.
    # Note that some server implementations have issues with the ArrayDimensions property, so it is not fetched at all if MaxArraySize is 0
    # -1 indicates that there is no limit to array lenght, though only 1-dimensional structures will be read either way.
    max-array-size: 0
    
    # Set to true to allow fetching string variables. This means that all variables with non-numeric type is converted to string in some way.
    allow-string-variables: false
    
    # Source node in the OPC-UA server. Leave empty to use the top level Objects node.
    root-node:
        # Full name of the namespace of the root node.
        namespace-uri:
        # Id of the root node, on the form "i=123" or "s=stringid" etc.
        node-id:

    # Override mappings between OPC UA node id and externalId, allowing e.g. the RootNode to be mapped to
    # a particular asset in CDF. Applies to both assets and time series.
    # NodeMap:
    #   "externalId": { NamespaceUri: "uri", NodeId: "i=123" }
    node-map:
  
    # Map OPC-UA namespaces to prefixes in CDF. If not mapped, the full namespace URI is used.
    # Saves space compared to using the full URL. Using the ns index is not safe as the order can change on the server.
    # For example:
    # NamespaceMap:
    #   "urn:cognite:net:server": cns
    #   "urn:freeopcua:python:server": fps
    #   "http://examples.freeopcua.github.io": efg
    namespace-map:

    # Add custom numeric types using their nodeId. IsStep indicates whether the datatype is discrete.
    # This also overwrite default behavior, so it is possible to make Integer discrete, etc.
    # Note that the type in question needs to have a sensible numerical conversion in C#, unless it is an array type or similar, 
    # in which case each element needs a conversion
    custom-numeric-types:
    #    - node-id: 
    #          namespace-uri:
    #          node-id:
    #      is-step: false
    # Time in minutes between each call to browse the OPC-UA directory, then push new nodes to destinations.
    # Note that this is a heavy operation, so this number should not be set too low.
    auto-rebrowse-period: 0
    # Enable using audit events to discover new nodes. If this is set to true, the client will expect AuditAddNodes/AuditAddReferences
    # events on the server node. These will be used to add new nodes automatically, by recursively browsing from each given ParentId.
    enable-audit-discovery:


events:
    # Event ids to map, with full namespace-uri, and node identifier on the form "i=123"
    # Custom events must be subtypes of the BaseEventType.
    event-ids:
        #-   namespace-uri:
        #    node-id:
    # Id of nodes to be observed as event emitters. Empty Namespace/NodeId defaults to the server node.
    emitter-ids:
        #-   namespace-uri:
        #    node-id:
    # List of BrowseName for properties to be excluded from automatic mapping to destination metadata.
    # All event properties are read, by default only "Time" and "Severity" are used from the base event.
    # Be aware that a maximum of 16 metadata entries are allowed in CDF.
    exclude-properties:
        #- Property1
        #- Property2
    # Map source browse names to other values in the destination. For CDF, internal properties may be overwritten, by default
    # "Message" is mapped to description, "SourceNode" is used for context and "EventType" is used for type. These may also be excluded or replaced by 
    # overrides in DestinationNameMap. If multiple properties are mapped to the same value, the first non-null is used.

    # If "StartTime", "EndTime" or "SubType" are specified, either directly or through the map, these are used as event properties instead of metadata.
    # StartTime and EndTime should be either DateTime, or a number corresponding to the number of milliseconds since January 1 1970.
    # If no StartTime or EndTime are specified, both are set to the "Time" property of BaseEventType.
    # "Type" may be overriden case-by-case using "NameOverrides" in Extraction configuration, or in a dynamic way here. If no "Type" is specified,
    # it is generated from Event NodeId in the same way ExternalIds are generated for normal nodes.
    destination-name-map:
        #Property1: SubType
    # Emitters that should be read for historical events. Leave empty to disable history read of events. Requires History.Enabled to be true.
    historizing-emitter-ids:
        #-   NamespaceUri:
        #    NodeId:
